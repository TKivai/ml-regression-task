{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TKivai/ml-regression-task/blob/master/linear_regression_GD_L1_regularized.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWnirnHrCCpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFFl84ujHpB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m=0       # initial start value of gradient\n",
        "c=0       # initial start value of y-intercept\n",
        "\n",
        "L=0.0001  # learning rate...try playing around with the value to see which ones converge\n",
        "alpha = 1000\n",
        "epoch=100 # define whatever number of epochs you want but mind both efficiency and accuracy issues\n",
        "\n",
        "lmbd = 0.01\n",
        "\n",
        "epoch_error_list=[]\n",
        "epoch_count_list=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk-G26o1JNN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=pd.read_csv('data.csv',header=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8WrYs1mJfE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=data['size_in_sq_ft']\n",
        "Y=data['price_x1000_sh']\n",
        "\n",
        "#y = mx + c\n",
        "\n",
        "N=float(len(X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OYiWvSlPehU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mse(N,Y,Y_hat):     # the MSE function for error computation\n",
        "  return (1/N)*sum(Y-Y_hat)**2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toAcxRKvKRDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gradient_descent_fit(m,c,N,L):    # main function i.e. gradient descent to learn the line of best fit\n",
        "  #y = mx + c\n",
        "\n",
        "  epoch_error_list=[]\n",
        "  epoch_count_list=[]\n",
        "\n",
        "  for i in range(epoch):#loop as many times as the epochs you want\n",
        "    Y_hat = m*X+c\n",
        "    #compute and arrest error for every iteration\n",
        "    epoch_count_list=epoch_count_list[:]#trick the list to get its instace\n",
        "    epoch_count_list.append(i)\n",
        "    \n",
        "    epoch_error=mse(N,Y,Y_hat)\n",
        "\n",
        "    epoch_error_list=epoch_error_list[:]\n",
        "    epoch_error_list.append(epoch_error)\n",
        "\n",
        "    #minimize the error function by computing partial derivatives\n",
        "    D_m=(-2/N)*sum(X*(Y-Y_hat))-alpha*(abs(m)/m)   #Getting the partial derivative of the regularized loss function using L1\n",
        "    \n",
        "    D_c=(-2/N)*sum(Y-Y_hat)\n",
        "    \n",
        "    #Apply gradient descent formular to update both m and c into new values\n",
        "    m=m-(L * D_m)\n",
        "    c=c-(L * D_c)\n",
        "  #you can print the final m and c after all iterations are done\n",
        "  print(\"final m is: \",m,\" and final c is: \",c)\n",
        "  #return final predicted value of Y-dependent variable\n",
        "  return Y_hat,epoch_count_list,epoch_error_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uakm4aI1R3Wg",
        "colab_type": "text"
      },
      "source": [
        "Getting the derivative of the L1 regularized loss function ****The link below contains an image of the handwritten derivation***\n",
        "(https://drive.google.com/file/d/1GxHUScsP86b1z48kYUP3-Nny8a9AuA1Y/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4v8OM-eMR9r",
        "colab_type": "code",
        "outputId": "c6aa7524-6edd-49ed-be49-a6f409dc9cc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        }
      },
      "source": [
        "#call gradient descent fit function\n",
        "returned_params=gradient_descent_fit(m,c,N,L)\n",
        "y_predicted=returned_params[0]\n",
        "total_epochs=returned_params[1]\n",
        "all_epoch_errors=returned_params[2]\n",
        "\n",
        "#create plot for both line of best fit and error reduction graphs\n",
        "fig,(ax1,ax2)=plt.subplots(2,gridspec_kw={'top':2})\n",
        "ax1.set(xlabel=\"Office size in Sq ft\")\n",
        "ax1.set(ylabel=\"Monthly Rent in Ksh. (X1000)\")\n",
        "ax1.set_title(\"Regression Model For Nairobi Office Prices.\\n\\n Graph 1 (Main): Line of Best Fit\")\n",
        "ax1.scatter(X,Y)\n",
        "\n",
        "ax1.plot([min(X),max(X)],[min(y_predicted),max(y_predicted)],color='black')\n",
        "ax2.set_title(\"Graph 2:MSE Monitoring Error Curve\")\n",
        "ax2.set(xlabel=\"Epochs/Iteration\")\n",
        "ax2.set(ylabel=\"Mean Squared Error\")\n",
        "ax2.plot(total_epochs,all_epoch_errors)\n",
        "\n",
        "#Destroy the used lists to prevent recarpetting on append\n",
        "epoch_count_list.clear()\n",
        "epoch_error_list.clear()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "linear_regression_GD_L1_regularized.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}